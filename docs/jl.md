## 简历
### 自我介绍模版
>我是谁 从业几年
> 会那些技术 平台 是否可以 0-1
> 擅长什么 实时？离线？
> 会什么语言，主要用在哪里
### 第一版
> 面试官你好我叫秦肖杨,目前从事数据开发已经有5年以上的开发经验了
> 对于线上产品阿里的dataworks,dataplin 线下集群CDH CDP都能够完成 
> 独立的搭建部署压测调优上线,开发语言主要使用java和python 
> java主要用于写一些flinksql,做一些flink项目,也可以实现从0-1的开发,
> pyhon主要用于爬虫，数据的清洗,脱敏,还有使用Python
> 用于数据预处理、脚本编写与自动化任务执行，如数据采集脚本、
> 数据验证脚本等等以上就是我的一个简单的自我介绍 谢谢面试官

# 实时

### ETL,ELT,ELK
#### ETL
>ETL（Extract, Transform, Load）是一种数据集成过程，用于将来自不同数据源的数据提取、转换和加载到目标系统中，
> 通常是一个数据仓库。它旨在确保数据的一致性和准确性，并为后续的数据分析和报告提供基础。
#### ELK
>ELK是三个开源工具Elasticsearch、Logstash和Kibana的组合，
> 用于从各种数据源收集、处理和可视化大量的日志数据。
> Elasticsearch是一个分布式搜索和分析引擎，Logstash是一个数据收集引擎，
> 用于将日志数据从不同源转移并传递到 Elasticsearch，
> 而 Kibana则是一个用于可视化这些数据的工具
#### ELT （Extract - Load - Transform）
> 提取（Extract）和加载（Load）：
> 转换（Transform）

### 数据源,数据通道(pipLine),target
#### pipline
### target

### 计算指标 为谁服务
### 状态服务 维度 join

## 离线
### sql复杂指标 数据建模方法论
### 设计优化 组件对比
### 对接报表

### mapjoin 
>也可以处理数据倾斜问题
> 
